# --- .github/workflows/reddit-injury-scraper.yml ---
name: Reddit & Craigslist Injury Scraper

on:
  workflow_dispatch:  # Manual trigger for testing

  # Runs every 6 hours (4 times per day)
  schedule:
    - cron: '0 */6 * * *'  # Every 6 hours: 12 AM, 6 AM, 12 PM, 6 PM UTC

jobs:
  scrape-injured-people:
    runs-on: ubuntu-latest
    
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: Run Reddit Scraper
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: python modules/legal_pi/reddit_injury_scraper.py
      
      - name: Wait 2 minutes (be respectful to servers)
        run: sleep 120
      
      - name: Run Craigslist Scraper
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: python modules/legal_pi/craigslist_scraper.py
      
      - name: Upload CSV artifacts (for manual review)
        uses: actions/upload-artifact@v4
        with:
          name: injury-leads-csv
          path: |
            reddit_injured_leads.csv
            craigslist_injured_leads.csv
          retention-days: 7
