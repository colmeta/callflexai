# This is the name of our automated job
name: Daily Prospecting and Analysis Agent

# This controls WHEN the job runs
on:
  # This allows us to run the workflow manually from the GitHub Actions tab
  workflow_dispatch:

  # This is the cron scheduler: runs at 05:30 UTC every day
  schedule:
    - cron: '30 5 * * *'

# This defines the actual STEPS the job will take
jobs:
  run-agent:
    # Use the latest version of Ubuntu Linux to run our job
    runs-on: ubuntu-latest

    steps:
      # Step 1: Check out a copy of our repository's code
      - name: Check out repository code
        uses: actions/checkout@v4

      # Step 2: Set up a Python environment
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      # Step 3: Install all the libraries our script needs
      - name: Install Python dependencies
        run: pip install -r requirements.txt

# NEW STEP: This will print the URL the agent is about to use.
      - name: DEBUG - Display Target Supabase URL
        run: echo "The agent is configured to connect to ${{ secrets.SUPABASE_URL }}"
        
      # Step 4: Run the main agent script
      - name: Execute the AI Prospector Agent
        env:
          SCRAPER_API_KEY: ${{ secrets.SERPAPI_API_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: python main.py
